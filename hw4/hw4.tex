\documentclass[twoside, letter]{article}
\setlength{\oddsidemargin}{0.01 in}
\setlength{\evensidemargin}{0.01 in}
\setlength{\topmargin}{-0.6 in}
\setlength{\textwidth}{6.5 in}
\setlength{\textheight}{8.5 in}
\setlength{\headsep}{0.75 in}
\setlength{\parindent}{0 in}
\setlength{\parskip}{0.1 in}

\usepackage{natbib}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\usepackage{pdfpages}

\usepackage{bbm}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\usepackage{caption}
\lstset{style=mystyle}
%
% ADD PACKAGES here:
%



\usepackage{amsmath,amsfonts,amssymb,graphicx,mathtools,flexisym}

%
% The following commands set up the lecnum (lecture number)
% counter and make various numbering schemes work relative
% to the lecture number.
%
\newcounter{lecnum}
\renewcommand{\thepage}{\thelecnum-\arabic{page}}
\renewcommand{\thesection}{\thelecnum.\arabic{section}}
\renewcommand{\theequation}{\thelecnum.\arabic{equation}}
\renewcommand{\thefigure}{\thelecnum.\arabic{figure}}
\renewcommand{\thetable}{\thelecnum.\arabic{table}}

%
% The following macro is used to generate the header.
%
\newcommand{\lecture}[4]{
   \pagestyle{myheadings}
   \thispagestyle{plain}
   \newpage
   \setcounter{lecnum}{#1}
   \setcounter{page}{1}
   \noindent
   \begin{center}
   \framebox{
      \vbox{\vspace{2mm}
    \hbox to 6.28in { {\bf STA 141C - Big Data \& High Performance Statistical Computing
	\hfill Spring 2022} }
       \vspace{4mm}
       \hbox to 6.28in { {\Large \hfill Homework 4 \hfill} }
       \vspace{2mm}
       %\hbox to 6.28in { {\it Lecturer: #3 \hfill Scribes: #4} }
       \hbox to 6.28in { {\it Lecturer: #2 \hfill  Due March 09, 2022} }
      \vspace{2mm}}
   }
   \end{center}
   \markboth{Homework #1: #2}{Homework #1: #2}

  % {\bf Note}: {\it LaTeX template courtesy of UC Berkeley EECS dept.}

}
%
% Convention for citations is authors' initials followed by the year.
% For example, to cite a paper by Leighton and Maggs you would type
% \cite{LM89}, and to cite a paper by Strassen you would type \cite{S69}.
% (To avoid bibliography problems, for now we redefine the \cite command.)
% Also commands that create a suitable format for the reference list.
\renewcommand{\cite}[1]{[#1]}
\def\beginrefs{\begin{list}%
        {[\arabic{equation}]}{\usecounter{equation}
         \setlength{\leftmargin}{2.0truecm}\setlength{\labelsep}{0.4truecm}%
         \setlength{\labelwidth}{1.6truecm}}}
\def\endrefs{\end{list}}
\def\bibentry#1{\item[\hbox{[#1]}]}

%Use this command for a figure; it puts a figure in wherever you want it.
%usage: \fig{NUMBER}{SPACE-IN-INCHES}{CAPTION}
\newcommand{\fig}[3]{
			\vspace{#2}
			\begin{center}
			Figure \thelecnum.#1:~#3
			\end{center}
	}
% Use these for theorems, lemmas, proofs, etc.
\newtheorem{theorem}{Theorem}[lecnum]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newenvironment{proof}{{\bf Proof:}}{\hfill\rule{2mm}{2mm}}

% **** IF YOU WANT TO DEFINE ADDITIONAL MACROS FOR YOURSELF, PUT THEM HERE:

\newcommand\E{\mathbb{E}}
\newcommand{\bitm}{\begin{itemize}}
\newcommand{\eitm}{\end{itemize}}
\newcommand{\blst}{\begin{lstlisting}}
\newcommand{\elst}{\end{lstlisting}}
\newcommand{\bfig}{\begin{figure}}
\newcommand{\efig}{\end{figure}}


\renewcommand{\thesection}{\arabic{section}}
\renewcommand{\thesubsection}{\thesection.\arabic{subsection}}
\renewcommand{\thesubsubsection}{\thesubsection.\arabic{subsubsection}}

\begin{document}
%FILL IN THE RIGHT INFO.
%\lecture{**LECTURE-NUMBER**}{**DATE**}{**LECTURER**}{**SCRIBE**}
\lecture{4}{Bo Y.-C. Ning}{Bo Y.-C. Ning}{}
%\footnotetext{These notes are partially based on those of Nigel Mansell.}

% **** YOUR NOTES GO HERE:
Due {\bf March 09, 2022} by 11:59pm. 

A few notes:
\begin{enumerate}
\item Submit your homework using the file name "{\bf LastName\_FirstName\_hw4}"

\item Answer all questions with complete sentences. 

\item Your code should be readable; writing a piece of code should be compared to writing a page of a book. Adopt the {\bf one-statement-per-line} rule. Consider splitting a lengthy statement into multiple lines to improve readability. (You will lose one point for each line that does not follow the one-statement-per-line rule)

\item To help understand and maintain code, you should always add comments to explain your code. (homework with no comments will receive 0 points). For a very long comment, break it into multiple lines.

\item Submit your final work with one {\bf .pdf} (or {\bf .html}) file to Canvas. I encourage you to use \href{http://www.docs.is.ed.ac.uk/skills/documents/3722/3722-2014.pdf}{\LaTeX} for writing equations. Handwriting is acceptable, you have to scan it and then combine it with the coding part into a single .pdf (or .html) file. Handwriting should be clean and readable.

\end{enumerate}


\section{Handwriting recognition}


In this homework,
we work on a model-based method for handwritten digit recognition. 
Following figure shows example bitmaps of handwritten digits from U.S. postal envelopes.

\begin{figure}[!h]
\centering
\includegraphics[width=0.6\textwidth]{handwriting}
\end{figure}

Each digit is represented by a $32 \times 32$ bitmap in which each element indicates one pixel with a
value of white or black. Each $32 \times 32$ bitmap is divided into blocks of $4 \times 4$, and the number of white pixels are counted in each block. Therefore each handwritten digit is summarized by a vector
$x = (x_1, \dots, x_{64})$ of length 64 where each element is a count between 0 and 16.

By a model-based method, we mean to impose a distribution on the count vector and carry
out classification using probabilities. The goal is to predict handwritten digit.
We separate the dataset into training data and test data. The training set contains 3823 handwritten digits
and the test set contains 1797 digits. 


A common distribution for count vectors is the multinomial
distribution. However, it is not a good model for handwritten digits.
Let's work on a more flexible model for count vectors,
the Dirichlet-multinomial model. 

For a multivariate count vector $x = (x_1, \dots, x_d)$ with batch size $|x| = \sum_{j=1}^d x_j$, the
probability mass function for Dirichlet-multinomial distribution is
$$
f(x  |  \alpha) = 
{|x| \choose x}
\frac{\prod_{j=1}^d (\alpha_j)_{x_j}}
{(|\alpha|)_{|x|}},
$$
where $ (a)_{k} = \prod_{i=0}^{k-1} (a +i)$.

%
%We assume the multinomial probabilities
%$p = (p_1, \dots, p_d)$ follow a Dirichlet distribution with parameter vector $\alpha = (\alpha_1, \dots, \alpha_d)$, $\alpha_j > 0$. The density function is 
%$$
%f(p|\alpha) = \frac{\Gamma(|\alpha|)}{\prod_{j=1}^d \Gamma(\alpha_j)}\prod_{j=1}^d p_j^{\alpha_j - 1},
%$$
%where $|\alpha| = \sum_{j=1}^d \alpha_j$ and $\Gamma(a) = (a-1)!$ is the gamma function.

Given independent data points $x_1, \dots, x_n$, the log-likelihood is given by 
$$
L(\alpha) = \sum_{i=1}^n \log {|x_i| \choose x_i} 
+ 
\sum_{i=1}^n \sum_{j=1}^d 
\left[
\log (\Gamma(\alpha_j + x_{ij}) - \log (\Gamma(\alpha_j))
\right]
- 
\sum_{i=1}^n \left[
\log \Gamma (|\alpha| + |x_i|) - \log \Gamma(|\alpha|)
\right].
$$

How do you calculate the MLE? 

In this exercise, we use Newton's method. First, the score function is given by 
$$
\frac{\partial}{\partial \alpha_j} L(\alpha)
= \sum_{i=1}^n \left[
\Psi (x_{ij} + \alpha_j) - \Psi (\alpha_j)
\right] -
\sum_{i=1}^n \left[
\Psi(|x_i| + |\alpha|) - \Psi(|\alpha|)
\right],
$$
where $\Psi(x) = d(\log \Gamma(x)) = \Gamma'(x)/ \Gamma(x)$.

Next, the observed information matrix is given by
$$
- d^2 L(\alpha) = D - c\mathbbm{1}_d \mathbbm{1}_d',
$$
where $D$ is a diagonal matrix,
$$
D_{jj} = \sum_{i=1}^n \left[\Psi'(\alpha_j) - \Psi'(x_{ij} + \alpha_j) \right]
=
\sum_{i=1}^n \sum_{k=0}^{x_{ij} - 1} \frac{1}{(\alpha_j + k)^2}
$$
and 
$$
c = \sum_{i=1}^n 
\left[
\Psi'(|\alpha|)  - \Psi'(|x_i| + |\alpha|) 
\right]
= \sum_{i=1}^n \sum_{k=0}^{|x_i| - 1} \frac{1}{(|\alpha| + k)^2}.
$$

Then given an initial value for $\alpha^{(0)}  = (\alpha_1^{(0)}, \dots, \alpha_n^{(0)})$, the Newton's method keep updating 
$$
\alpha^{(t)} = \alpha^{(t-1)} + [-d^2 L(\alpha^{(t-1)})]^{-1} d L(\alpha^{(t-1)})
$$
for $t = 1, \dots, T$. We stop when $|L(\alpha^{(t)}) - L(\alpha^{(t-1)})| \leq \epsilon$, and then take $\hat\alpha = \alpha^{(t)}$.

Note that $D$ is a diagonal matrix, we should use the Sherman-Morrison formula to write 
$$
[- d^2 L(\alpha)]^{-1} = D^{-1} + \frac{1}{1/c - \sum_j d_j^{-1}} D^{-1} \mathbbm{1} \mathbbm{1}' D^{-1}
$$


In the folder uploaded on Piazza, you will find 
\begin{itemize}
\item Data containing the training data and the testing data
\item `ddirmult.R', which evaluates the likelihood function (if log = FALSE) or the log-likelihood function (if log = TRUE) of the Dirichlet-multinomial density
\item `ddirmult.fit.R`, which estimates the maximum likelihood estimator (MLE) by Newton's method
\item `trainingMLE.R`, which estimates the MLE based on the training data
\end{itemize}

{\bf Question 1.} Open `trainingMLE.R' and obtain MLE estimators for each of the 10 handwriting digits $(0,1,2,\dots,9)$. (You may need to change the path when loading the data)

{\bf Question 2.} Read in the testing data. Use the estimated MLE for each digit from the training data to predict handwriting digits for the testing data. 
\begin{itemize}
\item Hint 1: To predict the handwriting digit, you should use the `ddirmult.R' function. 
The following code can be helpful 
\begin{lstlisting}[language=R]
# testDigitProb stores posterior probability of each digit being 0,1,...,9
testdata <- read.table("PATH/optdigits.tes", sep = ",")
testdata <- as.matrix(testdata)
testDigitProb <- matrix(0, dim(testdata)[1], 10)
for (dig in 0:9) {
  testDigitProb[, dig + 1] <-
    ddirmult(testdata[, -65], alphahat[dig + 1, ], log = TRUE)
}
testDigitProb <- testDigitProb +
  rep(log(digitCount / sum(digitCount)), each = nrow(testdata))
digitPredicted <- max.col(testDigitProb) - 1
\end{lstlisting}

\item Hint 2: To summarize the result, you can construct a confusion table using the code
\begin{lstlisting}[language = R]
table(testdata[, 65], digitPredicted)
\end{lstlisting}
The output should look like this:
\begin{figure}[!h]
\centering
\includegraphics[width=0.5\textwidth]{confusion-table}
\end{figure}
\end{itemize}

{\bf Question 3.} Comment on using gradient descent to obtain the MLE (instead of Newton's method)? (You do not need to implement this.) 


{\bf Question 4.} What is the advantage and disadvantage of using gradient descent instead of Newton's method?

{\bf Question 5.} Do you think the current method is satisfactory for predicting handwriting digits? Do you know any other method(s) that can achieve a higher accuracy? 

\end{document}